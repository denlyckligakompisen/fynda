name: Booli Daily Crawl

on:
  schedule:
    - cron: "0 5 * * *"   # 05:00 UTC (~06:00 Sverige)
  workflow_dispatch:

jobs:
  crawl:
    runs-on: ubuntu-latest

    env:
      START_URL: https://www.booli.se/sok/till-salu?areaIds=115355,35,883816,3377,2983,115351,874646,874654&floor=topFloor&maxListPrice=4000000&minLivingArea=45&upcomingSale=
      CRAWL_DELAY_SECONDS: "5"
      CACHE_TTL_HOURS: "12"
      CACHE_DIR: .cache/booli
      USER_AGENT: AntigravityCrawler/1.0 (daily; contact=you@example.com)

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Restore cache
        uses: actions/cache@v4
        with:
          path: .cache/booli
          key: booli-cache-${{ github.run_id }}
          restore-keys: |
            booli-cache-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run Booli Crawler (Stockholm Top Floor)
        run: |
          python scraper.py --url "${{ env.START_URL }}" --output booli_snapshot_topfloor.json

      - name: Run Booli Crawler (Stockholm General)
        env:
          STOCKHOLM_URL: "https://www.booli.se/sok/till-salu?areaIds=35,883816,115355,3377,2983,115351,874646,874654&maxListPrice=4000000&minLivingArea=45&upcomingSale="
        run: |
          python scraper.py --url "${{ env.STOCKHOLM_URL }}" --output booli_snapshot_stockholm.json

      - name: Run Booli Crawler (Uppsala General)
        env:
          UPPSALA_URL: "https://www.booli.se/sok/till-salu?areaIds=386699,386690,386688,870600&maxListPrice=4000000&minLivingArea=50&upcomingSale="
        run: |
          python scraper.py --url "${{ env.UPPSALA_URL }}" --output booli_snapshot_uppsala.json

      - name: Run Booli Crawler (Uppsala Top Floor)
        env:
          UPPSALA_TOP_URL: "https://www.booli.se/sok/till-salu?areaIds=386699,386690,386688,870600&floor=topFloor&maxListPrice=4000000&minLivingArea=50&upcomingSale="
        run: |
          python scraper.py --url "${{ env.UPPSALA_TOP_URL }}" --output booli_snapshot_uppsala_topfloor.json

      - name: Run Analyzer
        run: |
          # Analyze all snapshot files
          python analyze.py booli_snapshot_*.json

      - name: Upload snapshot artifact
        uses: actions/upload-artifact@v4
        with:
          name: booli-daily-snapshot
          path: |
            booli_snapshot_*.json
            src/data.json

      - name: Commit snapshot (optional)
        run: |
          git config user.name "github-actions"
          git config user.email "github-actions@github.com"
          git add src/data.json
          git commit -m "Daily Booli snapshot" || echo "No changes"
          git push
